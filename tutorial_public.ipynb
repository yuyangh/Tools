{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tutorial_public.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "F5HVtHKWLGTj",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "# SCP uploading and downloading"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0CU-cnEVLMQA",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "* go to server:\n",
        "     * type in terminal or command line \n",
        "     * ssh username@ip_address\n",
        "\n",
        "* download file instruction:\n",
        "    * scp username@servername:/path/filename /Users/mac/Desktop (local path)\n",
        "\n",
        "* upload file instruction:\n",
        "    * scp /path/filename username@servername:/path\n",
        "\n",
        "* download folder instruction:\n",
        "    * scp -r username@servername:/root/ (remote folder path) /Users/mac/Desktop (local path)\n",
        "\n",
        "* upload folder instruction:\n",
        "    * scp -r local_dir username@servername:remote_dir\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GImp2PcqL877",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "# [YOLO](https://pjreddie.com/darknet/yolo/): Real-Time Object Detection "
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Sdxp6LICMw5D",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "## YOLO training preparation"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eyF-heZpM4O4",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "*   generate labels and images\n",
        "    * put all .jpg/.jpeg images in folder called \"JPEGimages\"\n",
        "    * put all .txt labels in folder called \"labels\"\n",
        "      * json to yolo format can reference this [json2yolo.py](https://github.com/yuyangh/Tools/blob/master/json2yolo.py)\n",
        "    * \"JPEGimages\" and \"labels\" should be in the same directory\n",
        "*   create test/train split\n",
        "    * YOLO does not use validation part in training\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "UcloYCC0W028",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "**Code modification**\n",
        "* modify Makefile\n",
        "    * GPU\u003d1 to support GPU\n",
        "    * CUDNN\u003d1 to support CUDA\n",
        "    * OpenCV \u003d 0, only when image needs OpenCV\u0027s support, then open OpenCV\n",
        "*  modify model file /cfg/yolov3.cfg \n",
        "      * batch \u003d number of samples in 1 batch\n",
        "      * subdivisions \u003d xxx means divide 1 batch to xxx subdivisions to load into GPU. \n",
        "        * Fewer subdivisions require less video memory and train slower\n",
        "      * if image size is smaller than yolov3\u0027s default size, \n",
        "        * change width\u003d416, height\u003d416 so that model size is smaller than image size\n",
        "      * max_batches \u003d XXX, max_batches is the maximum iterations going to be trained\n",
        "        * value depend on batch size: Ideally, our model expect to train up to 200-300 epoch.\n",
        "        * iterations \u003d num_epoch * (num_images/batch_size)\n",
        "        * e.g. num_epoch \u003d 200, batch_size \u003d 64, num_images \u003d 8862, iterations \u003d 200 * (8862/64) ~ 30k iterations\n",
        "      * for all yolo layers, change classes \u0026 filters\n",
        "        * classes \u003d number of classes you have in dataset\n",
        "        * filters \u003d (classes +5) * 3 because 5 includes object ID and bounding box\n",
        "      * e.g. for yolov3, there are 3 yolo layers\n",
        "*   modify cfg/xxx.data (similar to coco.data)\n",
        "      * specify where your data is\n",
        "      * backup\u003d folder where you would like to backup, usually there is already a folder in /darknet/\n",
        "      * eval\u003dcoco, this is the evaluation method, since we are not using that, comment this line\n",
        "*  modify  data/xxx.names (similar to data/coco.names)\n",
        "*  modify examples/detector.c\n",
        "      * add find_replace(labelpath,\".jpeg\",\".txt\", labelpath); to support .jpeg images:\n",
        "      * examples/detectors.c, on line 138, i%NUM, NUM is how frequently saved\n",
        "* any update in .c files need to type **\"make\"** in darknet/ to update"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YPtUP_TpXYMk",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "**Start training with command: **\n",
        "* make sure nobody is using that GPU before training\n",
        "\n",
        "```\n",
        "./darknet detector train cfg/flir_adas.data cfg/yolov3.cfg darknet53.conv.74 -gpus 0 \u0026\u003e train_output.txt\n",
        "```\n",
        "\n",
        "paramerters: \n",
        "*   cfg/yolov3.cfg is the model file\n",
        "*   darknet53.conv.74 is pre-trained weights with specific choosen layers\n",
        "*   -gpus 0 is choose which GPU to do training\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "w9ll5gMQZ625",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "## YOLO training process parameter meaning"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VU0frA2hZ_qX",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "* Region Avg IOU: \n",
        "  * average IOU represen the percent of intersection over union of predicted bounding box and ground truth. \n",
        "  * we expect it to approximate 1\n",
        "* Class:\n",
        "  * the probability to be the labeled object\n",
        "  * we expect it to approximate 1\n",
        "* Obj:\n",
        "  * we expect it be approximate 1\n",
        "* No Obj:\n",
        "  * expect value should be decreasing but not 0\n",
        "* Avg Recall\n",
        "  * expect value approximate 0\n",
        "* avgï¼š\n",
        "  * average loss, expect it be 0"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "AvQrD0_H7ivy",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "## YOLO performance evaluation"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Knfy7xb97s_H",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "*  copy yolov3.cfg to yolov3-test.cfg and modify\n    * batch \u003d1\n    * subdivision \u003d1\n*  modify examples/Detector.c to do validation\n    * in validate_detector_recall() function:  \n    * modify threshold:  float thresh \u003d .25;  \n    * change validation path around line 496  \n      * list *plist \u003d get_paths(\"/mnt/large4t/pengchong_data/Data/Paul/filelist/val.txt\");\n    \n* start evaluation\n  * provided in validation.sh\n  * ./darknet detector recall cfg/flir_adas.data cfg/yolov3.cfg backup/yolov3_final.weights -gpus 0 \u0026\u003e validation_output.txt\n* measure mAP\n  * git clone https://github.com/Cartucho/mAP.git\n  * in extra/, \n    * for ground-truth, run  convert convert_gt_yolo.py to do ground-truth conversion\n    * for detection-results, follow the guide. if darknet does not support \"-dont_show\" command, clone https://github.com/AlexeyAB/darknet.git, this repo supports the command\n    * to change the thresh in predicton, go to src/detector.c and find \"float thresh \u003d find_float_arg(argc, argv, \"-thresh\", .25);\" to change .25 value\n    * remember to change the IMG_FORMAT \u003d \u0027.jpg\u0027 to your image format\n    * ./darknet detector test cfg/flir_adas.data cfg/yolov3-test.cfg backup/yolov3_30000.weights -gpus 0 -dont_show -ext_output \u003c data/flir_adas_valid.list \u003e result.txt  \n  * run main.py\n     \n\n\n"
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ZXWdHYaMFnqF",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "## YOLO single image detection"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "X1r7BIB6Frao",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "* detection command\n",
        "  * ./darknet detect cfg/yolov3.cfg backup/yolov3_final.weights ../FLIR_ADAS/validation/PreviewData/FLIR_08863.jpeg  \n",
        "* download prediction image  \n",
        "  * scp server_path:/data/projects/FireSpotter/darknet/predictions.jpg \"E:\\markh\\Downloads\"  "
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Wbm-mIiUS_ZF",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "# Server Command"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TV3IyPxtUo9e",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "## Screening"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-NGQElS-U2Hn",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "* Why we use this? \n",
        "  * When our laptop goes to sleep or turns off, the connection to the server will be closed and session will be lost.  \n",
        "  * To let the server save the connection, we need screening.\n",
        "---\n",
        "* Command\n",
        "  * screen -S \"name\": attach to screen with \"name\"\n",
        "  * screen -dr \"name\": switch back to command line\n",
        "  * screen -ls: ls all screens\n",
        "  * control A + control D: leave screen\n",
        "  * exit: exit screen\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "KU46k4OMUlQ8",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "## Nvidia GPU"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4rWrO2iMTWFb",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "* see GPU info: nvidia-smi\n",
        "* watch GPU info: watch nvidia-smi"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6M4azB_1CaYe",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "# Install ubuntu on PC"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "cJsrVfOi8ICV",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "## preparation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "r7rESrZEEEGu",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "* an empty hard disk with over 128 GB for the Linux system\n",
        "* download ubantu operating system\n",
        "    * recommend using  [ubuntu LTS version]( https://www.ubuntu.com/download/desktop )\n",
        "    * choose -amd64.iso if your computer is 64 bits system\n",
        "* have an empty flash driver with at least 4 GB space\n",
        "    * remember to backup files\n",
        "* use [rufus](https://rufus.ie/) to write the Linux operating system into the flash driver\n",
        "    * in partition scheme, choose UEFI if your mother board supports UEFI, otherwise, choose MBR\n",
        "        * UEFI will make the system opens faster\n",
        "    * here is how to do the format\n",
        "    * NOTICE: once start formating, all contents in the flash driver will be erased\n",
        "* ![alt text](https://rufus.ie/pics/rufus_en.png)"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "gbcYJbOLCLVu",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "## install the ubuntu system\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VXJwhVC1EZna",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "*   go into the BIOS\n",
        "    * depends on different brands, might be ESC, F2, F10, or 12\n",
        "    * press one of those buttions many times after pressing the power on button\n",
        "* BIOS set up\n",
        "    * TURN OFF the secure boot!!!\n",
        "    * this is very important, otherwise graphics driver may not install succcessful later\n",
        "    * choose UEFI BIOS if your flash driver is in UEFI mode\n",
        "    * put flash driver as the first one in boot order"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "fVTxeLMaTCQO",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "# Vim Commands"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "2QKOzIvdTGS0",
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": [
        "*   search: /\n",
        "*   search next: n\n",
        "*   undo: u\n",
        "* go the end of file: shift+G"
      ]
    }
  ]
}